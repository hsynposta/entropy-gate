{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {"provenance": [], "gpuType": "T4"},
  "kernelspec": {"name": "python3", "display_name": "Python 3"},
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Geometric–Entropy Gating — CIFAR-10-C Benchmark\n",
    "\n",
    "**Paper:** Huseyin Aydin (2025) — [https://doi.org/10.5281/zenodo.18055798](https://doi.org/10.5281/zenodo.18055798)\n",
    "\n",
    "**What this notebook does:**\n",
    "1. Trains a ResNet-18 baseline (standard cross-entropy)\n",
    "2. Trains a Gated ResNet-18 (Hybrid Geometric–Entropy loss)\n",
    "3. Evaluates both on **CIFAR-10-C** — 19 corruption types × 5 severity levels\n",
    "4. Compares accuracy + ECE (calibration error)\n",
    "\n",
    "**Key design:** Gate distances are computed in ResNet-18 **feature space** (512-dim avgpool),\n",
    "not raw pixel space — this makes the geometric gate meaningful for images.\n",
    "\n",
    "> ⚡ Enable GPU: Runtime → Change runtime type → T4 GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Setup ─────────────────────────────────────────────────────────────────────\n",
    "!pip install -q git+https://github.com/hsynposta/entropy-gate.git\n",
    "\n",
    "# CIFAR-10-C (corrupted test sets) — ~2.5 GB\n",
    "import os\n",
    "if not os.path.exists('CIFAR-10-C'):\n",
    "    print('Downloading CIFAR-10-C (~2.5 GB)...')\n",
    "    !wget -q https://zenodo.org/record/2535967/files/CIFAR-10-C.tar\n",
    "    !tar -xf CIFAR-10-C.tar\n",
    "    print('Done.')\n",
    "else:\n",
    "    print('CIFAR-10-C already downloaded.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Imports ───────────────────────────────────────────────────────────────────\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from entropy_gate.gates import GeometricGate, EntropyGate, HybridGate\n",
    "from entropy_gate.loss  import GatedLoss\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {DEVICE}')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Config ────────────────────────────────────────────────────────────────────\n",
    "EPOCHS      = 60\n",
    "BATCH       = 128\n",
    "LR          = 1e-3\n",
    "WARMUP      = 10       # epochs before gate activates\n",
    "ALPHA       = 4.0      # geometric gate steepness\n",
    "BETA        = 4.0      # entropy gate steepness\n",
    "N_CLASSES   = 10\n",
    "\n",
    "CORRUPTIONS = [\n",
    "    'gaussian_noise','shot_noise','impulse_noise','defocus_blur',\n",
    "    'glass_blur','motion_blur','zoom_blur','snow','frost','fog',\n",
    "    'brightness','contrast','elastic_transform','pixelate',\n",
    "    'jpeg_compression','speckle_noise','gaussian_blur','spatter','saturate'\n",
    "]\n",
    "SEVERITIES = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Data loading ──────────────────────────────────────────────────────────────\n",
    "MEAN = (0.4914, 0.4822, 0.4465)\n",
    "STD  = (0.2023, 0.1994, 0.2010)\n",
    "\n",
    "train_tfm = T.Compose([\n",
    "    T.RandomCrop(32, padding=4),\n",
    "    T.RandomHorizontalFlip(),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(MEAN, STD),\n",
    "])\n",
    "test_tfm = T.Compose([T.ToTensor(), T.Normalize(MEAN, STD)])\n",
    "\n",
    "train_ds = torchvision.datasets.CIFAR10('.', train=True,  download=True, transform=train_tfm)\n",
    "test_ds  = torchvision.datasets.CIFAR10('.', train=False, download=True, transform=test_tfm)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "test_dl  = DataLoader(test_ds,  batch_size=256,   shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "print(f'Train: {len(train_ds):,}  |  Test (clean): {len(test_ds):,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── ResNet-18 with feature extraction hook ─────────────────────────────────────\n",
    "class GatableResNet18(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet-18 that also exposes 512-dim feature vectors from avgpool.\n",
    "    Used to compute geometric gate distances in feature space.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        base = resnet18(weights=None)\n",
    "        self.backbone = nn.Sequential(*list(base.children())[:-1])  # up to avgpool\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        feat = self.backbone(x).flatten(1)   # (N, 512)\n",
    "        logits = self.classifier(feat)        # (N, C)\n",
    "        if return_features:\n",
    "            return logits, feat\n",
    "        return logits\n",
    "\n",
    "    def features(self, x):\n",
    "        with torch.no_grad():\n",
    "            return self.backbone(x).flatten(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Compute training feature center (for geometric gate) ──────────────────────\n",
    "@torch.no_grad()\n",
    "def compute_feature_center(model, loader, device):\n",
    "    \"\"\"Compute mean and 75th-percentile radius of training features.\"\"\"\n",
    "    model.eval()\n",
    "    feats = []\n",
    "    for x, _ in tqdm(loader, desc='Computing feature center', leave=False):\n",
    "        feats.append(model.features(x.to(device)).cpu())\n",
    "    feats  = torch.cat(feats)\n",
    "    center = feats.mean(0)\n",
    "    dists  = torch.norm(feats - center, dim=1)\n",
    "    radius = float(torch.quantile(dists, 0.75))\n",
    "    return center.to(device), radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Evaluation helpers ─────────────────────────────────────────────────────────\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_conf, all_acc = [], []\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        probs = torch.softmax(model(x), dim=1)\n",
    "        conf, pred = probs.max(1)\n",
    "        acc_batch  = (pred == y).float()\n",
    "        correct   += acc_batch.sum().item()\n",
    "        total     += len(y)\n",
    "        all_conf.append(conf.cpu()); all_acc.append(acc_batch.cpu())\n",
    "    all_conf = torch.cat(all_conf); all_acc = torch.cat(all_acc)\n",
    "    # ECE\n",
    "    bins = torch.linspace(0, 1, 11)\n",
    "    ece  = 0.0\n",
    "    for lo, hi in zip(bins[:-1], bins[1:]):\n",
    "        m = (all_conf > lo) & (all_conf <= hi)\n",
    "        if m.sum() > 0:\n",
    "            ece += m.sum().item() * abs(all_acc[m].mean() - all_conf[m].mean()).item()\n",
    "    return correct / total, ece / total\n",
    "\n",
    "def load_cifar10c(corruption, severity, normalize=True):\n",
    "    \"\"\"Load one corruption/severity from CIFAR-10-C as a DataLoader.\"\"\"\n",
    "    data   = np.load(f'CIFAR-10-C/{corruption}.npy')  # (50000, 32, 32, 3)\n",
    "    labels = np.load('CIFAR-10-C/labels.npy')          # (50000,)\n",
    "    # Each severity is 10000 samples\n",
    "    idx    = slice((severity - 1) * 10000, severity * 10000)\n",
    "    X = torch.from_numpy(data[idx]).permute(0, 3, 1, 2).float() / 255.0\n",
    "    if normalize:\n",
    "        mean = torch.tensor(MEAN).view(3,1,1)\n",
    "        std  = torch.tensor(STD).view(3,1,1)\n",
    "        X    = (X - mean) / std\n",
    "    y = torch.from_numpy(labels[idx]).long()\n",
    "    return DataLoader(TensorDataset(X, y), batch_size=256, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Training: Baseline ─────────────────────────────────────────────────────────\n",
    "print('=' * 60)\n",
    "print('  Training BASELINE (standard cross-entropy)')\n",
    "print('=' * 60)\n",
    "\n",
    "baseline = GatableResNet18(N_CLASSES).to(DEVICE)\n",
    "opt_b    = torch.optim.SGD(baseline.parameters(), lr=0.1, momentum=0.9,\n",
    "                            weight_decay=5e-4, nesterov=True)\n",
    "sched_b  = torch.optim.lr_scheduler.CosineAnnealingLR(opt_b, T_max=EPOCHS)\n",
    "ce_loss  = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    baseline.train()\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        loss = ce_loss(baseline(x), y)\n",
    "        opt_b.zero_grad(); loss.backward(); opt_b.step()\n",
    "    sched_b.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        acc, ece = evaluate(baseline, test_dl, DEVICE)\n",
    "        print(f'  Epoch {epoch+1:3d}/{EPOCHS} | acc={acc:.3f} | ece={ece*100:.2f}%')\n",
    "\n",
    "torch.save(baseline.state_dict(), 'baseline.pth')\n",
    "print('Baseline saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Training: Gated ResNet-18 ──────────────────────────────────────────────────\n",
    "print('=' * 60)\n",
    "print('  Training GATED ResNet-18 (Hybrid Geometric-Entropy Gate)')\n",
    "print('=' * 60)\n",
    "\n",
    "gated   = GatableResNet18(N_CLASSES).to(DEVICE)\n",
    "opt_g   = torch.optim.SGD(gated.parameters(), lr=0.1, momentum=0.9,\n",
    "                           weight_decay=5e-4, nesterov=True)\n",
    "sched_g = torch.optim.lr_scheduler.CosineAnnealingLR(opt_g, T_max=EPOCHS)\n",
    "\n",
    "geo_gate    = GeometricGate(alpha=ALPHA).to(DEVICE)\n",
    "ent_gate    = EntropyGate(beta=BETA, num_classes=N_CLASSES).to(DEVICE)\n",
    "hybrid_gate = HybridGate(geo_gate, ent_gate,\n",
    "                          warmup_steps=WARMUP * len(train_dl)).to(DEVICE)\n",
    "gate_loss   = GatedLoss(hybrid_gate)\n",
    "\n",
    "# Compute feature center after warmup for geometric gate calibration\n",
    "train_center = None\n",
    "train_radius = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    gated.train()\n",
    "\n",
    "    # Calibrate gate after warmup using current features\n",
    "    if epoch == WARMUP:\n",
    "        print(f'  Calibrating geometric gate at epoch {epoch}...')\n",
    "        train_center, train_radius = compute_feature_center(gated, train_dl, DEVICE)\n",
    "        geo_gate.log_d0.data = torch.tensor(train_radius).log().to(DEVICE)\n",
    "        print(f'  Gate radius d0 = {train_radius:.3f}')\n",
    "\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits, feats = gated(x, return_features=True)\n",
    "\n",
    "        # Feature-space distances for geometric gate\n",
    "        if train_center is not None:\n",
    "            dists = torch.norm(feats - train_center, dim=1).detach()\n",
    "        else:\n",
    "            dists = torch.ones(len(x), device=DEVICE)  # during warmup: all weight=1\n",
    "\n",
    "        loss = gate_loss(logits, y, dists)\n",
    "        opt_g.zero_grad(); loss.backward(); opt_g.step()\n",
    "        hybrid_gate.step()\n",
    "\n",
    "    sched_g.step()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        acc, ece = evaluate(gated, test_dl, DEVICE)\n",
    "        status = 'WARMUP' if epoch < WARMUP else 'ACTIVE'\n",
    "        print(f'  Epoch {epoch+1:3d}/{EPOCHS} | acc={acc:.3f} | ece={ece*100:.2f}% | gate={status}')\n",
    "\n",
    "torch.save(gated.state_dict(), 'gated.pth')\n",
    "print('Gated model saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── CIFAR-10-C Evaluation ─────────────────────────────────────────────────────\n",
    "print('Evaluating on CIFAR-10-C (19 corruptions × 5 severities)...')\n",
    "print('This takes ~5 minutes.')\n",
    "\n",
    "results = {}\n",
    "for corr in tqdm(CORRUPTIONS, desc='Corruptions'):\n",
    "    results[corr] = {'base_acc':[], 'gate_acc':[], 'base_ece':[], 'gate_ece':[]}\n",
    "    for sev in SEVERITIES:\n",
    "        dl_c = load_cifar10c(corr, sev)\n",
    "        ba, be = evaluate(baseline, dl_c, DEVICE)\n",
    "        ga, ge = evaluate(gated,    dl_c, DEVICE)\n",
    "        results[corr]['base_acc'].append(ba)\n",
    "        results[corr]['gate_acc'].append(ga)\n",
    "        results[corr]['base_ece'].append(be)\n",
    "        results[corr]['gate_ece'].append(ge)\n",
    "\n",
    "# Clean test set\n",
    "clean_base_acc, clean_base_ece = evaluate(baseline, test_dl, DEVICE)\n",
    "clean_gate_acc, clean_gate_ece = evaluate(gated,    test_dl, DEVICE)\n",
    "\n",
    "print(f'\\nClean test: Baseline {clean_base_acc:.3f} | Gated {clean_gate_acc:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Results table ─────────────────────────────────────────────────────────────\n",
    "print(f'\\n{\"=\"*70}')\n",
    "print(f'  {\"Corruption\":25s}  {\"Base Acc\":>10}  {\"Gate Acc\":>10}  {\"Δ Acc\":>8}')\n",
    "print(f'  {\"─\"*65}')\n",
    "\n",
    "all_deltas = []\n",
    "for corr in CORRUPTIONS:\n",
    "    bm = np.mean(results[corr]['base_acc'])\n",
    "    gm = np.mean(results[corr]['gate_acc'])\n",
    "    d  = gm - bm\n",
    "    all_deltas.append(d)\n",
    "    arrow = '▲' if d > 0.005 else ('▼' if d < -0.005 else '─')\n",
    "    print(f'  {corr:25s}  {bm*100:>8.1f}%  {gm*100:>8.1f}%  {arrow}{abs(d)*100:>5.1f}pp')\n",
    "\n",
    "print(f'  {\"─\"*65}')\n",
    "print(f'  {\"AVERAGE (all corruptions)\":25s}  '\n",
    "      f'{np.mean([np.mean(results[c][\"base_acc\"]) for c in CORRUPTIONS])*100:>8.1f}%  '\n",
    "      f'{np.mean([np.mean(results[c][\"gate_acc\"]) for c in CORRUPTIONS])*100:>8.1f}%  '\n",
    "      f'{np.mean(all_deltas)*100:>+6.2f}pp')\n",
    "print(f'  {\"Clean test\":25s}  {clean_base_acc*100:>8.1f}%  {clean_gate_acc*100:>8.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Visualization ─────────────────────────────────────────────────────────────\n",
    "DARK=\"#0f1117\"; GRID=\"#1e2130\"; BASE=\"#e74c3c\"\n",
    "GATE=\"#2ecc71\"; GOLD=\"#f1c40f\"; TEXT=\"#ecf0f1\"; SUB=\"#95a5a6\"\n",
    "\n",
    "# Per-corruption mean accuracies\n",
    "base_means = [np.mean(results[c]['base_acc']) * 100 for c in CORRUPTIONS]\n",
    "gate_means = [np.mean(results[c]['gate_acc']) * 100 for c in CORRUPTIONS]\n",
    "deltas_pp  = [g - b for g, b in zip(gate_means, base_means)]\n",
    "\n",
    "# Per-severity averages\n",
    "sev_base = [np.mean([results[c]['base_acc'][s] for c in CORRUPTIONS]) for s in range(5)]\n",
    "sev_gate = [np.mean([results[c]['gate_acc'][s] for c in CORRUPTIONS]) for s in range(5)]\n",
    "sev_base_ece = [np.mean([results[c]['base_ece'][s] for c in CORRUPTIONS]) for s in range(5)]\n",
    "sev_gate_ece = [np.mean([results[c]['gate_ece'][s] for c in CORRUPTIONS]) for s in range(5)]\n",
    "\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "fig.patch.set_facecolor(DARK)\n",
    "gs  = gridspec.GridSpec(2, 2, figure=fig, hspace=0.45, wspace=0.35)\n",
    "\n",
    "def style(ax, title):\n",
    "    ax.set_facecolor(GRID); ax.tick_params(colors=SUB, labelsize=9)\n",
    "    ax.spines[:].set_color('#2c3e50')\n",
    "    ax.set_title(title, color=TEXT, fontsize=10, fontweight='bold', pad=8)\n",
    "    ax.xaxis.label.set_color(SUB); ax.yaxis.label.set_color(SUB)\n",
    "\n",
    "# A — per-corruption bars\n",
    "ax1 = fig.add_subplot(gs[0, :])\n",
    "x   = np.arange(len(CORRUPTIONS))\n",
    "w   = 0.35\n",
    "ax1.bar(x - w/2, base_means, w, color=BASE, label='Baseline', alpha=0.85)\n",
    "ax1.bar(x + w/2, gate_means, w, color=GATE, label='Gated',    alpha=0.85)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([c.replace('_', '\\n') for c in CORRUPTIONS],\n",
    "                     fontsize=7, color=SUB)\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "ax1.legend(facecolor=DARK, edgecolor='#2c3e50', labelcolor=TEXT)\n",
    "style(ax1, f'A  Accuracy per Corruption Type (avg over 5 severities)  |  Avg Δ = {np.mean(deltas_pp):+.2f} pp')\n",
    "\n",
    "# B — accuracy vs severity\n",
    "ax2 = fig.add_subplot(gs[1, 0])\n",
    "sevs = [1,2,3,4,5]\n",
    "ax2.plot(sevs, [v*100 for v in sev_base], 'o-', color=BASE, lw=2.5, ms=7, label='Baseline')\n",
    "ax2.plot(sevs, [v*100 for v in sev_gate], 's-', color=GATE, lw=2.5, ms=7, label='Gated')\n",
    "ax2.fill_between(sevs,\n",
    "                  [v*100 for v in sev_base],\n",
    "                  [v*100 for v in sev_gate],\n",
    "                  alpha=0.1, color=GATE)\n",
    "ax2.set_xlabel('Corruption Severity'); ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend(facecolor=DARK, edgecolor='#2c3e50', labelcolor=TEXT, fontsize=9)\n",
    "style(ax2, 'B  Accuracy vs Severity (avg over all corruptions)')\n",
    "\n",
    "# C — ECE vs severity\n",
    "ax3 = fig.add_subplot(gs[1, 1])\n",
    "ax3.plot(sevs, [v*100 for v in sev_base_ece], 'o-', color=BASE, lw=2.5, ms=7, label='Baseline ECE')\n",
    "ax3.plot(sevs, [v*100 for v in sev_gate_ece], 's-', color=GATE, lw=2.5, ms=7, label='Gated ECE')\n",
    "ax3.set_xlabel('Corruption Severity'); ax3.set_ylabel('ECE (%) — lower is better')\n",
    "ax3.legend(facecolor=DARK, edgecolor='#2c3e50', labelcolor=TEXT, fontsize=9)\n",
    "style(ax3, 'C  Calibration Error vs Severity')\n",
    "\n",
    "avg_ood_base = np.mean([np.mean(results[c]['base_acc']) for c in CORRUPTIONS])\n",
    "avg_ood_gate = np.mean([np.mean(results[c]['gate_acc']) for c in CORRUPTIONS])\n",
    "\n",
    "fig.suptitle(\n",
    "    'Hybrid Geometric–Entropy Gating  ·  Aydin 2025\\n'\n",
    "    f'CIFAR-10-C Benchmark  |  ResNet-18  |  '\n",
    "    f'OOD acc: {avg_ood_base*100:.1f}% → {avg_ood_gate*100:.1f}% '\n",
    "    f'({np.mean(deltas_pp):+.2f} pp)  |  '\n",
    "    f'github.com/hsynposta/entropy-gate',\n",
    "    color=TEXT, fontsize=11, fontweight='bold', y=0.98\n",
    ")\n",
    "\n",
    "plt.savefig('cifar10c_benchmark.png', dpi=150, bbox_inches='tight',\n",
    "            facecolor=fig.get_facecolor())\n",
    "plt.show()\n",
    "print('Figure saved: cifar10c_benchmark.png')"
   ]
  }
 ]
}
