{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {"provenance": [], "gpuType": "T4"},
  "kernelspec": {"name": "python3", "display_name": "Python 3"},
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid Geometric–Entropy Gating — Contaminated Training Benchmark\n",
    "\n",
    "**Paper:** Huseyin Aydin (2025) — [https://doi.org/10.5281/zenodo.18055798](https://doi.org/10.5281/zenodo.18055798)\n",
    "\n",
    "## The key scenario\n",
    "\n",
    "Real-world training sets are rarely clean. This notebook tests whether the Hybrid Gate\n",
    "can **automatically identify and downweight noisy training samples** — without any\n",
    "manual data cleaning.\n",
    "\n",
    "- **Training data**: CIFAR-10 + 30% contaminated samples (random labels + heavy noise)\n",
    "- **Both models see identical (dirty) training data**\n",
    "- **Test**: clean CIFAR-10 test set + CIFAR-10-C corruptions\n",
    "- **Hypothesis**: Gate should downweight noisy samples → better generalization\n",
    "\n",
    "> ⚡ Runtime → Change runtime type → **T4 GPU**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Setup ─────────────────────────────────────────────────────────────────────\n",
    "!pip install -q git+https://github.com/hsynposta/entropy-gate.git\n",
    "\n",
    "import os\n",
    "if not os.path.exists('CIFAR-10-C'):\n",
    "    print('Downloading CIFAR-10-C (~2.5 GB)...')\n",
    "    !wget -q https://zenodo.org/record/2535967/files/CIFAR-10-C.tar\n",
    "    !tar -xf CIFAR-10-C.tar\n",
    "    print('Done.')\n",
    "else:\n",
    "    print('CIFAR-10-C already present.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Imports ───────────────────────────────────────────────────────────────────\n",
    "import torch, torch.nn as nn, torch.nn.functional as F\n",
    "import torchvision, torchvision.transforms as T\n",
    "from torchvision.models import resnet18\n",
    "from torch.utils.data import DataLoader, TensorDataset, Dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from entropy_gate.gates import GeometricGate, EntropyGate, HybridGate\n",
    "from entropy_gate.loss  import GatedLoss\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Device: {DEVICE}')\n",
    "torch.manual_seed(42); np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Config ────────────────────────────────────────────────────────────────────\n",
    "EPOCHS         = 80\n",
    "BATCH          = 128\n",
    "LR             = 0.1\n",
    "WARMUP         = 12        # epochs before gate activates\n",
    "ALPHA          = 4.0\n",
    "BETA           = 4.0\n",
    "NOISE_RATIO    = 0.30      # 30% of training samples contaminated\n",
    "NOISE_SIGMA    = 0.8       # noise magnitude (in normalized space)\n",
    "N_CLASSES      = 10\n",
    "\n",
    "CORRUPTIONS = [\n",
    "    'gaussian_noise','shot_noise','impulse_noise','defocus_blur',\n",
    "    'glass_blur','motion_blur','zoom_blur','snow','frost','fog',\n",
    "    'brightness','contrast','elastic_transform','pixelate',\n",
    "    'jpeg_compression','speckle_noise','gaussian_blur','spatter','saturate'\n",
    "]\n",
    "SEVERITIES = [1, 2, 3, 4, 5]\n",
    "MEAN = (0.4914, 0.4822, 0.4465)\n",
    "STD  = (0.2023, 0.1994, 0.2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Contaminated dataset ──────────────────────────────────────────────────────\n",
    "class ContaminatedCIFAR10(Dataset):\n",
    "    \"\"\"\n",
    "    CIFAR-10 training set with NOISE_RATIO fraction contaminated:\n",
    "    - Pixel noise added (NOISE_SIGMA in normalized space)\n",
    "    - Labels randomized to wrong classes\n",
    "    The gate should automatically learn to downweight these.\n",
    "    \"\"\"\n",
    "    def __init__(self, noise_ratio=0.30, noise_sigma=0.8, seed=42, augment=True):\n",
    "        rng = np.random.RandomState(seed)\n",
    "        base = torchvision.datasets.CIFAR10('.', train=True, download=True)\n",
    "        X = torch.from_numpy(base.data).permute(0,3,1,2).float() / 255.0\n",
    "        # Normalize\n",
    "        mn = torch.tensor(MEAN).view(3,1,1)\n",
    "        sd = torch.tensor(STD).view(3,1,1)\n",
    "        X  = (X - mn) / sd\n",
    "        y  = torch.tensor(base.targets, dtype=torch.long)\n",
    "\n",
    "        # Contaminate\n",
    "        n_bad = int(len(X) * noise_ratio)\n",
    "        bad_idx = rng.permutation(len(X))[:n_bad]\n",
    "        X[bad_idx] += torch.from_numpy(\n",
    "            rng.randn(n_bad, 3, 32, 32).astype(np.float32)) * noise_sigma\n",
    "        y[bad_idx] = torch.from_numpy(\n",
    "            rng.randint(0, N_CLASSES, n_bad).astype(np.int64))\n",
    "\n",
    "        self.X, self.y = X, y\n",
    "        self.augment   = augment\n",
    "        self.aug = T.Compose([\n",
    "            T.RandomCrop(32, padding=4),\n",
    "            T.RandomHorizontalFlip(),\n",
    "        ])\n",
    "        print(f'Contaminated dataset: {len(X):,} samples '\n",
    "              f'({n_bad:,} noisy = {noise_ratio:.0%})')\n",
    "\n",
    "    def __len__(self): return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.X[idx], self.y[idx]\n",
    "        if self.augment:\n",
    "            x = self.aug(x)\n",
    "        return x, y\n",
    "\n",
    "train_ds_c = ContaminatedCIFAR10(NOISE_RATIO, NOISE_SIGMA)\n",
    "train_dl   = DataLoader(train_ds_c, batch_size=BATCH, shuffle=True,\n",
    "                         num_workers=2, pin_memory=True)\n",
    "\n",
    "# Clean test set\n",
    "test_tfm = T.Compose([T.ToTensor(), T.Normalize(MEAN, STD)])\n",
    "test_ds  = torchvision.datasets.CIFAR10('.', train=False, download=True, transform=test_tfm)\n",
    "test_dl  = DataLoader(test_ds, batch_size=256, shuffle=False,\n",
    "                       num_workers=2, pin_memory=True)\n",
    "print(f'Clean test: {len(test_ds):,} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Model ─────────────────────────────────────────────────────────────────────\n",
    "class GatableResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super().__init__()\n",
    "        base = resnet18(weights=None)\n",
    "        self.backbone   = nn.Sequential(*list(base.children())[:-1])\n",
    "        self.classifier = nn.Linear(512, num_classes)\n",
    "\n",
    "    def forward(self, x, return_features=False):\n",
    "        feat   = self.backbone(x).flatten(1)\n",
    "        logits = self.classifier(feat)\n",
    "        return (logits, feat) if return_features else logits\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def features(self, x):\n",
    "        return self.backbone(x).flatten(1)\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_center(model, loader, device):\n",
    "    model.eval()\n",
    "    feats = torch.cat([model.features(x.to(device)).cpu()\n",
    "                       for x, _ in tqdm(loader, desc='Feature center', leave=False)])\n",
    "    center = feats.mean(0)\n",
    "    radius = float(torch.quantile(torch.norm(feats - center, dim=1), 0.75))\n",
    "    return center.to(device), radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Evaluation helpers ─────────────────────────────────────────────────────────\n",
    "@torch.no_grad()\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    all_conf, all_acc = [], []\n",
    "    for x, y in loader:\n",
    "        x, y  = x.to(device), y.to(device)\n",
    "        probs  = torch.softmax(model(x), dim=1)\n",
    "        conf, pred = probs.max(1)\n",
    "        acc_b  = (pred == y).float()\n",
    "        correct += acc_b.sum().item(); total += len(y)\n",
    "        all_conf.append(conf.cpu()); all_acc.append(acc_b.cpu())\n",
    "    all_conf = torch.cat(all_conf); all_acc = torch.cat(all_acc)\n",
    "    bins = torch.linspace(0, 1, 11)\n",
    "    ece  = sum(m.sum().item() * abs(all_acc[m].mean() - all_conf[m].mean()).item()\n",
    "               for lo, hi in zip(bins[:-1], bins[1:])\n",
    "               if (m := (all_conf > lo) & (all_conf <= hi)).sum() > 0) / total\n",
    "    return correct / total, ece\n",
    "\n",
    "def load_cifar10c(corruption, severity):\n",
    "    data   = np.load(f'CIFAR-10-C/{corruption}.npy')\n",
    "    labels = np.load('CIFAR-10-C/labels.npy')\n",
    "    idx    = slice((severity-1)*10000, severity*10000)\n",
    "    X = torch.from_numpy(data[idx]).permute(0,3,1,2).float() / 255.0\n",
    "    mn = torch.tensor(MEAN).view(3,1,1)\n",
    "    sd = torch.tensor(STD).view(3,1,1)\n",
    "    X  = (X - mn) / sd\n",
    "    y  = torch.from_numpy(labels[idx]).long()\n",
    "    return DataLoader(TensorDataset(X, y), batch_size=256, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Train BASELINE ─────────────────────────────────────────────────────────────\n",
    "print('='*60)\n",
    "print(f'  BASELINE  |  {NOISE_RATIO:.0%} contaminated training data')\n",
    "print('='*60)\n",
    "\n",
    "baseline = GatableResNet18().to(DEVICE)\n",
    "opt_b    = torch.optim.SGD(baseline.parameters(), lr=LR, momentum=0.9,\n",
    "                            weight_decay=5e-4, nesterov=True)\n",
    "sched_b  = torch.optim.lr_scheduler.CosineAnnealingLR(opt_b, T_max=EPOCHS)\n",
    "ce_loss  = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    baseline.train()\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        opt_b.zero_grad()\n",
    "        ce_loss(baseline(x), y).backward()\n",
    "        opt_b.step()\n",
    "    sched_b.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        acc, ece = evaluate(baseline, test_dl, DEVICE)\n",
    "        print(f'  Epoch {epoch+1:3d}/{EPOCHS} | acc={acc:.3f} | ece={ece*100:.2f}%')\n",
    "\n",
    "torch.save(baseline.state_dict(), 'baseline_contaminated.pth')\n",
    "print('Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Train GATED ────────────────────────────────────────────────────────────────\n",
    "print('='*60)\n",
    "print(f'  GATED  |  {NOISE_RATIO:.0%} contaminated training data')\n",
    "print('='*60)\n",
    "\n",
    "gated   = GatableResNet18().to(DEVICE)\n",
    "opt_g   = torch.optim.SGD(gated.parameters(), lr=LR, momentum=0.9,\n",
    "                           weight_decay=5e-4, nesterov=True)\n",
    "sched_g = torch.optim.lr_scheduler.CosineAnnealingLR(opt_g, T_max=EPOCHS)\n",
    "\n",
    "geo_gate    = GeometricGate(alpha=ALPHA).to(DEVICE)\n",
    "ent_gate    = EntropyGate(beta=BETA, num_classes=N_CLASSES).to(DEVICE)\n",
    "hybrid_gate = HybridGate(geo_gate, ent_gate,\n",
    "                          warmup_steps=WARMUP*len(train_dl)).to(DEVICE)\n",
    "gate_loss   = GatedLoss(hybrid_gate)\n",
    "\n",
    "train_center = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    gated.train()\n",
    "\n",
    "    if epoch == WARMUP:\n",
    "        print(f'  Calibrating gate at epoch {epoch}...')\n",
    "        train_center, radius = compute_center(gated, train_dl, DEVICE)\n",
    "        geo_gate.log_d0.data = torch.tensor(radius).log().to(DEVICE)\n",
    "        print(f'  d0 = {radius:.3f}')\n",
    "\n",
    "    for x, y in train_dl:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        logits, feats = gated(x, return_features=True)\n",
    "\n",
    "        dists = (torch.norm(feats - train_center, dim=1).detach()\n",
    "                 if train_center is not None\n",
    "                 else torch.ones(len(x), device=DEVICE))\n",
    "\n",
    "        opt_g.zero_grad()\n",
    "        gate_loss(logits, y, dists).backward()\n",
    "        opt_g.step()\n",
    "        hybrid_gate.step()\n",
    "\n",
    "    sched_g.step()\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        acc, ece = evaluate(gated, test_dl, DEVICE)\n",
    "        status = 'WARMUP' if epoch < WARMUP else 'ACTIVE'\n",
    "        print(f'  Epoch {epoch+1:3d}/{EPOCHS} | acc={acc:.3f} | ece={ece*100:.2f}% | [{status}]')\n",
    "\n",
    "torch.save(gated.state_dict(), 'gated_contaminated.pth')\n",
    "print('Saved.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Evaluate on CIFAR-10-C ────────────────────────────────────────────────────\n",
    "print('Evaluating on CIFAR-10-C...')\n",
    "\n",
    "results = {c: {'base_acc':[],'gate_acc':[],'base_ece':[],'gate_ece':[]}\n",
    "           for c in CORRUPTIONS}\n",
    "\n",
    "for corr in tqdm(CORRUPTIONS):\n",
    "    for sev in SEVERITIES:\n",
    "        dl = load_cifar10c(corr, sev)\n",
    "        ba, be = evaluate(baseline, dl, DEVICE)\n",
    "        ga, ge = evaluate(gated,    dl, DEVICE)\n",
    "        results[corr]['base_acc'].append(ba)\n",
    "        results[corr]['gate_acc'].append(ga)\n",
    "        results[corr]['base_ece'].append(be)\n",
    "        results[corr]['gate_ece'].append(ge)\n",
    "\n",
    "clean_ba, clean_be = evaluate(baseline, test_dl, DEVICE)\n",
    "clean_ga, clean_ge = evaluate(gated,    test_dl, DEVICE)\n",
    "\n",
    "print(f'Clean → Baseline: {clean_ba:.3f}  |  Gated: {clean_ga:.3f}  '\n",
    "      f'(Δ={( clean_ga-clean_ba)*100:+.2f}pp)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Results table ─────────────────────────────────────────────────────────────\n",
    "print(f'\\n{\"=\"*65}')\n",
    "print(f'  {\"Corruption\":25s}  {\"Base\":>8}  {\"Gated\":>8}  {\"Δ\":>8}')\n",
    "print(f'  {\"-\"*60}')\n",
    "\n",
    "deltas = []\n",
    "for c in CORRUPTIONS:\n",
    "    bm = np.mean(results[c]['base_acc'])\n",
    "    gm = np.mean(results[c]['gate_acc'])\n",
    "    d  = gm - bm; deltas.append(d)\n",
    "    arr = '▲' if d > 0.005 else ('▼' if d < -0.005 else '─')\n",
    "    print(f'  {c:25s}  {bm*100:>6.1f}%  {gm*100:>6.1f}%  {arr}{abs(d)*100:>5.1f}pp')\n",
    "\n",
    "avg_b = np.mean([np.mean(results[c]['base_acc']) for c in CORRUPTIONS])\n",
    "avg_g = np.mean([np.mean(results[c]['gate_acc']) for c in CORRUPTIONS])\n",
    "print(f'  {\"-\"*60}')\n",
    "print(f'  {\"AVERAGE\":25s}  {avg_b*100:>6.1f}%  {avg_g*100:>6.1f}%  {(avg_g-avg_b)*100:>+6.2f}pp')\n",
    "print(f'  {\"Clean test\":25s}  {clean_ba*100:>6.1f}%  {clean_ga*100:>6.1f}%  {(clean_ga-clean_ba)*100:>+6.2f}pp')\n",
    "print(f'\\n  Training contamination: {NOISE_RATIO:.0%}')\n",
    "print(f'  Overall OOD gain: {np.mean(deltas)*100:+.2f} pp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Figure ────────────────────────────────────────────────────────────────────\n",
    "DARK='#0f1117';GRID='#1e2130';BASE='#e74c3c'\n",
    "GATE='#2ecc71';TEXT='#ecf0f1';SUB='#95a5a6'\n",
    "\n",
    "def style(ax, title):\n",
    "    ax.set_facecolor(GRID); ax.tick_params(colors=SUB, labelsize=9)\n",
    "    ax.spines[:].set_color('#2c3e50')\n",
    "    ax.set_title(title, color=TEXT, fontsize=10, fontweight='bold', pad=8)\n",
    "    ax.xaxis.label.set_color(SUB); ax.yaxis.label.set_color(SUB)\n",
    "\n",
    "base_means = [np.mean(results[c]['base_acc'])*100 for c in CORRUPTIONS]\n",
    "gate_means = [np.mean(results[c]['gate_acc'])*100 for c in CORRUPTIONS]\n",
    "delta_pp   = [g-b for g,b in zip(gate_means, base_means)]\n",
    "\n",
    "sev_b = [np.mean([results[c]['base_acc'][s] for c in CORRUPTIONS])*100 for s in range(5)]\n",
    "sev_g = [np.mean([results[c]['gate_acc'][s] for c in CORRUPTIONS])*100 for s in range(5)]\n",
    "sev_be= [np.mean([results[c]['base_ece'][s] for c in CORRUPTIONS])*100 for s in range(5)]\n",
    "sev_ge= [np.mean([results[c]['gate_ece'][s] for c in CORRUPTIONS])*100 for s in range(5)]\n",
    "\n",
    "fig = plt.figure(figsize=(18, 12))\n",
    "fig.patch.set_facecolor(DARK)\n",
    "gs  = gridspec.GridSpec(2, 2, figure=fig, hspace=0.45, wspace=0.35)\n",
    "\n",
    "# A — per corruption\n",
    "ax1 = fig.add_subplot(gs[0,:])\n",
    "x = np.arange(len(CORRUPTIONS)); w = 0.35\n",
    "ax1.bar(x-w/2, base_means, w, color=BASE, label='Baseline', alpha=0.85)\n",
    "ax1.bar(x+w/2, gate_means, w, color=GATE, label='Gated',    alpha=0.85)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([c.replace('_','\\n') for c in CORRUPTIONS], fontsize=7, color=SUB)\n",
    "ax1.set_ylabel('Accuracy (%)')\n",
    "ax1.legend(facecolor=DARK, edgecolor='#2c3e50', labelcolor=TEXT)\n",
    "style(ax1, f'A  Per-Corruption Accuracy  |  {NOISE_RATIO:.0%} train contamination  '\n",
    "      f'|  Avg Δ = {np.mean(delta_pp):+.2f} pp')\n",
    "\n",
    "# B — vs severity\n",
    "ax2 = fig.add_subplot(gs[1,0])\n",
    "sevs = [1,2,3,4,5]\n",
    "ax2.plot(sevs, sev_b, 'o-', color=BASE, lw=2.5, ms=7, label='Baseline')\n",
    "ax2.plot(sevs, sev_g, 's-', color=GATE, lw=2.5, ms=7, label='Gated')\n",
    "ax2.fill_between(sevs, sev_b, sev_g, alpha=0.1,\n",
    "                  color=GATE if np.mean(delta_pp)>0 else BASE)\n",
    "ax2.set_xlabel('Severity'); ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend(facecolor=DARK, edgecolor='#2c3e50', labelcolor=TEXT, fontsize=9)\n",
    "style(ax2, 'B  Accuracy vs Severity')\n",
    "\n",
    "# C — ECE vs severity\n",
    "ax3 = fig.add_subplot(gs[1,1])\n",
    "ax3.plot(sevs, sev_be, 'o-', color=BASE, lw=2.5, ms=7, label='Baseline ECE')\n",
    "ax3.plot(sevs, sev_ge, 's-', color=GATE, lw=2.5, ms=7, label='Gated ECE')\n",
    "ax3.fill_between(sevs, sev_be, sev_ge, alpha=0.1, color=GATE)\n",
    "ax3.set_xlabel('Severity'); ax3.set_ylabel('ECE (%) — lower is better')\n",
    "ax3.legend(facecolor=DARK, edgecolor='#2c3e50', labelcolor=TEXT, fontsize=9)\n",
    "style(ax3, 'C  Calibration Error vs Severity')\n",
    "\n",
    "fig.suptitle(\n",
    "    'Hybrid Geometric–Entropy Gating  ·  Aydin 2025\\n'\n",
    "    f'CIFAR-10-C  |  ResNet-18  |  {NOISE_RATIO:.0%} train contamination  '\n",
    "    f'|  OOD: {avg_b:.1%} → {avg_g:.1%} ({(avg_g-avg_b)*100:+.2f}pp)  '\n",
    "    f'|  Clean: {clean_ba:.1%} → {clean_ga:.1%}',\n",
    "    color=TEXT, fontsize=11, fontweight='bold', y=0.98\n",
    ")\n",
    "\n",
    "plt.savefig('cifar10c_contaminated.png', dpi=150, bbox_inches='tight',\n",
    "            facecolor=fig.get_facecolor())\n",
    "plt.show()\n",
    "print('Figure saved: cifar10c_contaminated.png')"
   ]
  }
 ]
}